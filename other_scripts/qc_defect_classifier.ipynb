{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Defect Classifier\n",
    "Multi-label defect detection model for photo quality assessment.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Upload & extract training data zip\n",
    "2. Load labels and build data pipeline\n",
    "3. Train MobileNetV2 (frozen head â†’ fine-tune)\n",
    "4. Evaluate with per-defect threshold tuning\n",
    "5. Export models (.h5, SavedModel, TFLite) + config JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import (\n",
    "    classification_report, multilabel_confusion_matrix,\n",
    "    precision_recall_curve, f1_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload & Extract Data\n",
    "Expected zip structure:\n",
    "```\n",
    "sorted/\n",
    "  labels.csv\n",
    "  good/\n",
    "  bad/\n",
    "  unreadable/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your training data zip (images/ folder + labels.csv):\")\n",
    "uploaded = files.upload()\n",
    "zip_filename = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded: {zip_filename}\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, \"r\") as z:\n",
    "    z.extractall(\"training_data\")\n",
    "\n",
    "# Auto-detect structure\n",
    "if os.path.isfile(\"training_data/labels.csv\"):\n",
    "    DATA_DIR = \"training_data\"\n",
    "elif os.path.isfile(\"training_data/sorted/labels.csv\"):\n",
    "    DATA_DIR = \"training_data/sorted\"\n",
    "else:\n",
    "    for root, dirs, _files in os.walk(\"training_data\"):\n",
    "        for d in dirs:\n",
    "            print(os.path.join(root, d))\n",
    "    raise FileNotFoundError(\"Could not find labels.csv. Check your zip structure.\")\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_HEAD = 10\n",
    "EPOCHS_FT = 20\n",
    "SEED = 42\n",
    "DEFAULT_THRESHOLD = 0.5\n",
    "TOP_K = 3\n",
    "\n",
    "IMG_DIR = DATA_DIR\n",
    "LABEL_FILE = os.path.join(DATA_DIR, \"labels.csv\")\n",
    "\n",
    "DEFECT_NAMES = [\n",
    "    \"blur\", \"glare\", \"shadow\", \"angle\",\n",
    "    \"cropped\", \"too_far\", \"too_close\", \"low_contrast\"\n",
    "]\n",
    "NUM_DEFECTS = len(DEFECT_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Labels & Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABEL_FILE)\n",
    "\n",
    "image_paths = df[\"filename\"].apply(lambda x: os.path.join(IMG_DIR, x)).values\n",
    "labels = df[DEFECT_NAMES].values.astype(\"float32\")\n",
    "\n",
    "print(\"Defect distribution:\")\n",
    "for i, name in enumerate(DEFECT_NAMES):\n",
    "    count = int(labels[:, i].sum())\n",
    "    pct = count / len(labels) * 100\n",
    "    print(f\"  {name:15s} {count:5d} ({pct:.1f}%)\")\n",
    "print(f\"  {'TOTAL IMAGES':15s} {len(labels):5d}\")\n",
    "\n",
    "# Train/val split\n",
    "np.random.seed(SEED)\n",
    "idx = np.random.permutation(len(image_paths))\n",
    "split = int(0.8 * len(idx))\n",
    "\n",
    "train_idx, val_idx = idx[:split], idx[split:]\n",
    "x_train, y_train = image_paths[train_idx], labels[train_idx]\n",
    "x_val, y_val = image_paths[val_idx], labels[val_idx]\n",
    "\n",
    "print(f\"\\nTrain: {len(x_train)} | Val: {len(x_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "for images, batch_labels in train_ds.take(1):\n",
    "    for i in range(min(12, len(images))):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        active = [DEFECT_NAMES[j] for j in range(NUM_DEFECTS) if batch_labels[i][j] > 0.5]\n",
    "        title = \", \".join(active) if active else \"no defects\"\n",
    "        plt.title(title, fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Training Images\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"preview_training_samples.png\", dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved preview_training_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomBrightness(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"Base model layers: {len(base_model.layers)}\")\n",
    "print(f\"Base model params: {base_model.count_params():,}\")\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(NUM_DEFECTS, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"qc_defect_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Train Head (Base Frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"bin_acc\"),\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Phase 1: Training classification head (base frozen)...\")\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_HEAD,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Fine-Tune Top Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "fine_tune_from = 100\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "trainable_count = sum(1 for l in base_model.layers if l.trainable)\n",
    "print(f\"Fine-tuning {trainable_count} of {len(base_model.layers)} base layers\")\n",
    "\n",
    "early_stop_ft = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "reduce_lr_ft = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"bin_acc\"),\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Phase 2: Fine-tuning top layers...\")\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_FT,\n",
    "    callbacks=[early_stop_ft, reduce_lr_ft],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_histories(h1, h2):\n",
    "    combined = {}\n",
    "    for key in h1.history:\n",
    "        combined[key] = h1.history[key] + h2.history[key]\n",
    "    return combined\n",
    "\n",
    "history = combine_histories(history1, history2)\n",
    "phase1_epochs = len(history1.history[\"loss\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(history[\"bin_acc\"], label=\"Train\")\n",
    "axes[0].plot(history[\"val_bin_acc\"], label=\"Validation\")\n",
    "axes[0].axvline(x=phase1_epochs - 0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Fine-tune start\")\n",
    "axes[0].set_title(\"Binary Accuracy\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history[\"auc\"], label=\"Train\")\n",
    "axes[1].plot(history[\"val_auc\"], label=\"Validation\")\n",
    "axes[1].axvline(x=phase1_epochs - 0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Fine-tune start\")\n",
    "axes[1].set_title(\"AUC\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"AUC\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(history[\"loss\"], label=\"Train\")\n",
    "axes[2].plot(history[\"val_loss\"], label=\"Validation\")\n",
    "axes[2].axvline(x=phase1_epochs - 0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Fine-tune start\")\n",
    "axes[2].set_title(\"Loss\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Training History\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_history.png\", dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Collect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "y_true_list = []\n",
    "y_pred_raw_list = []\n",
    "\n",
    "for images, batch_labels in val_ds:\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    y_true_list.append(batch_labels.numpy())\n",
    "    y_pred_raw_list.append(preds)\n",
    "\n",
    "y_true = np.concatenate(y_true_list, axis=0)\n",
    "y_pred_raw = np.concatenate(y_pred_raw_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Defect Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true_col, y_pred_col, default=DEFAULT_THRESHOLD):\n",
    "    \"\"\"Find threshold that maximizes F1 for a single defect column.\"\"\"\n",
    "    if y_true_col.sum() == 0:\n",
    "        return default\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_col, y_pred_col)\n",
    "    precision = precision[:-1]\n",
    "    recall = recall[:-1]\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        f1_scores = np.where(\n",
    "            (precision + recall) > 0,\n",
    "            2 * (precision * recall) / (precision + recall),\n",
    "            0.0,\n",
    "        )\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    return float(thresholds[best_idx])\n",
    "\n",
    "per_defect_thresholds = {}\n",
    "print(\"Per-defect optimal thresholds (maximizing F1):\")\n",
    "print(\"-\" * 55)\n",
    "for i, name in enumerate(DEFECT_NAMES):\n",
    "    best_t = find_best_threshold(y_true[:, i], y_pred_raw[:, i])\n",
    "    per_defect_thresholds[name] = round(best_t, 3)\n",
    "    positives = int(y_true[:, i].sum())\n",
    "    print(f\"  {name:15s}  threshold={best_t:.3f}  (positives={positives})\")\n",
    "\n",
    "threshold_array = np.array([per_defect_thresholds[n] for n in DEFECT_NAMES])\n",
    "y_pred_tuned = (y_pred_raw >= threshold_array).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "for i, name in enumerate(DEFECT_NAMES):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    if y_true[:, i].sum() > 0:\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true[:, i], y_pred_raw[:, i])\n",
    "        ax.plot(recall, precision, linewidth=2)\n",
    "        best_t = per_defect_thresholds[name]\n",
    "        best_pred = (y_pred_raw[:, i] >= best_t).astype(int)\n",
    "        bp = precision_score(y_true[:, i], best_pred, zero_division=0)\n",
    "        br = recall_score(y_true[:, i], best_pred, zero_division=0)\n",
    "        ax.plot(br, bp, \"ro\", markersize=8, label=f\"t={best_t:.2f}\")\n",
    "        ax.legend(fontsize=9)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No positives\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "    ax.set_title(name, fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    ax.set_xlim([0, 1.05])\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Precision-Recall Curves (red dot = tuned threshold)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"precision_recall_curves.png\", dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved precision_recall_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report (per-defect tuned thresholds):\")\n",
    "print(\"-\" * 55)\n",
    "print(classification_report(\n",
    "    y_true.astype(int),\n",
    "    y_pred_tuned,\n",
    "    target_names=DEFECT_NAMES,\n",
    "    zero_division=0,\n",
    "))\n",
    "\n",
    "y_pred_global = (y_pred_raw >= DEFAULT_THRESHOLD).astype(int)\n",
    "f1_global = f1_score(y_true.astype(int), y_pred_global, average=\"macro\", zero_division=0)\n",
    "f1_tuned = f1_score(y_true.astype(int), y_pred_tuned, average=\"macro\", zero_division=0)\n",
    "print(f\"Macro F1 with global threshold (0.5): {f1_global:.4f}\")\n",
    "print(f\"Macro F1 with tuned thresholds:       {f1_tuned:.4f}\")\n",
    "print(f\"Improvement:                           {(f1_tuned - f1_global):+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Defect Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcm = multilabel_confusion_matrix(y_true.astype(int), y_pred_tuned)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "for i, (cm, name) in enumerate(zip(mcm, DEFECT_NAMES)):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    im = ax.imshow(cm, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "    t = per_defect_thresholds[name]\n",
    "    ax.set_title(f\"{name} (t={t:.2f})\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"No\", \"Yes\"])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels([\"No\", \"Yes\"])\n",
    "    for row in range(2):\n",
    "        for col in range(2):\n",
    "            ax.text(col, row, str(cm[row, col]),\n",
    "                    ha=\"center\", va=\"center\", fontsize=14,\n",
    "                    color=\"white\" if cm[row, col] > cm.max() / 2 else \"black\")\n",
    "\n",
    "plt.suptitle(\"Per-Defect Confusion Matrices (tuned thresholds)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrices.png\", dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "shown = 0\n",
    "for images, batch_labels in val_ds:\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    for i in range(len(images)):\n",
    "        if shown >= 16:\n",
    "            break\n",
    "        ax = plt.subplot(4, 4, shown + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "        true_defects = [DEFECT_NAMES[j] for j in range(NUM_DEFECTS) if batch_labels[i][j] > 0.5]\n",
    "        pred_defects = [\n",
    "            DEFECT_NAMES[j] for j in range(NUM_DEFECTS)\n",
    "            if preds[i][j] >= per_defect_thresholds[DEFECT_NAMES[j]]\n",
    "        ]\n",
    "\n",
    "        true_str = \", \".join(true_defects) if true_defects else \"none\"\n",
    "        pred_str = \", \".join(pred_defects) if pred_defects else \"none\"\n",
    "        match = set(true_defects) == set(pred_defects)\n",
    "\n",
    "        plt.title(f\"T: {true_str}\\nP: {pred_str}\", fontsize=7,\n",
    "                  color=\"green\" if match else \"red\")\n",
    "        plt.axis(\"off\")\n",
    "        shown += 1\n",
    "    if shown >= 16:\n",
    "        break\n",
    "\n",
    "plt.suptitle(\"Sample Predictions (green=exact match, red=mismatch)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sample_predictions.png\", dpi=100)\n",
    "plt.show()\n",
    "print(\"Saved sample_predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = \"qc_defect_model.h5\"\n",
    "model.save(h5_path)\n",
    "h5_size = os.path.getsize(h5_path) / (1024 * 1024)\n",
    "print(f\"Saved Keras model: {h5_path} ({h5_size:.1f} MB)\")\n",
    "\n",
    "saved_model_dir = \"qc_defect_model\"\n",
    "model.save(saved_model_dir)\n",
    "print(f\"Saved TF SavedModel: {saved_model_dir}/\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = \"qc_defect_model.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "tflite_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
    "print(f\"Saved TFLite model: {tflite_path} ({tflite_size:.1f} MB)\")\n",
    "print(f\"Size reduction: {h5_size / tflite_size:.1f}x smaller than .h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Thresholds & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"defect_names\": DEFECT_NAMES,\n",
    "    \"per_defect_thresholds\": per_defect_thresholds,\n",
    "    \"default_threshold\": DEFAULT_THRESHOLD,\n",
    "    \"top_k\": TOP_K,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"severity_weights\": {\n",
    "        \"blur\": 0.9,\n",
    "        \"glare\": 0.7,\n",
    "        \"shadow\": 0.5,\n",
    "        \"angle\": 0.8,\n",
    "        \"cropped\": 1.0,\n",
    "        \"too_far\": 0.8,\n",
    "        \"too_close\": 0.6,\n",
    "        \"low_contrast\": 0.4,\n",
    "    },\n",
    "}\n",
    "\n",
    "config_path = \"qc_model_config.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(model_config, f, indent=2)\n",
    "print(f\"Saved model config: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models & Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading models, config, and plots...\")\n",
    "files.download(h5_path)\n",
    "files.download(tflite_path)\n",
    "files.download(config_path)\n",
    "files.download(\"training_history.png\")\n",
    "files.download(\"precision_recall_curves.png\")\n",
    "files.download(\"confusion_matrices.png\")\n",
    "files.download(\"sample_predictions.png\")\n",
    "files.download(\"preview_training_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_photo_quality(image_path, model, config):\n",
    "    \"\"\"\n",
    "    Production-ready inference for a single photo.\n",
    "\n",
    "    Returns a dict structured for Laravel / API / mobile consumption:\n",
    "    {\n",
    "        \"filename\": \"photo_001.jpg\",\n",
    "        \"overall_quality\": \"fail\",       # \"pass\" or \"fail\"\n",
    "        \"severity_score\": 0.82,          # 0.0 (clean) to 1.0 (worst)\n",
    "        \"defects_flagged\": [             # defects that crossed their threshold\n",
    "            {\"name\": \"blur\", \"confidence\": 0.91, \"threshold\": 0.42},\n",
    "            {\"name\": \"angle\", \"confidence\": 0.73, \"threshold\": 0.38}\n",
    "        ],\n",
    "        \"top_k_risks\": [                 # top K defects by confidence, even if below threshold\n",
    "            {\"name\": \"blur\", \"confidence\": 0.91},\n",
    "            {\"name\": \"angle\", \"confidence\": 0.73},\n",
    "            {\"name\": \"glare\", \"confidence\": 0.28}\n",
    "        ],\n",
    "        \"all_scores\": {                  # raw sigmoid outputs\n",
    "            \"blur\": 0.91, \"glare\": 0.28\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    thresholds = config[\"per_defect_thresholds\"]\n",
    "    defect_names = config[\"defect_names\"]\n",
    "    severity_weights = config[\"severity_weights\"]\n",
    "    top_k = config.get(\"top_k\", TOP_K)\n",
    "    img_size = config.get(\"img_size\", IMG_SIZE)\n",
    "\n",
    "    img = keras.utils.load_img(image_path, target_size=(img_size, img_size))\n",
    "    img_array = np.expand_dims(keras.utils.img_to_array(img), axis=0)\n",
    "    raw_preds = model.predict(img_array, verbose=0)[0]\n",
    "\n",
    "    all_scores = {name: round(float(raw_preds[i]), 4) for i, name in enumerate(defect_names)}\n",
    "\n",
    "    defects_flagged = []\n",
    "    for i, name in enumerate(defect_names):\n",
    "        t = thresholds.get(name, DEFAULT_THRESHOLD)\n",
    "        if raw_preds[i] >= t:\n",
    "            defects_flagged.append({\n",
    "                \"name\": name,\n",
    "                \"confidence\": round(float(raw_preds[i]), 4),\n",
    "                \"threshold\": t,\n",
    "            })\n",
    "    defects_flagged.sort(key=lambda d: d[\"confidence\"], reverse=True)\n",
    "\n",
    "    sorted_defects = sorted(\n",
    "        [(name, float(raw_preds[i])) for i, name in enumerate(defect_names)],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "    top_k_risks = [\n",
    "        {\"name\": name, \"confidence\": round(conf, 4)}\n",
    "        for name, conf in sorted_defects[:top_k]\n",
    "    ]\n",
    "\n",
    "    weighted_sum = sum(raw_preds[i] * severity_weights.get(name, 0.5)\n",
    "                       for i, name in enumerate(defect_names))\n",
    "    max_possible = sum(severity_weights.get(name, 0.5) for name in defect_names)\n",
    "    severity_score = round(float(weighted_sum / max_possible), 4)\n",
    "\n",
    "    return {\n",
    "        \"filename\": os.path.basename(image_path),\n",
    "        \"overall_quality\": \"fail\" if defects_flagged else \"pass\",\n",
    "        \"severity_score\": severity_score,\n",
    "        \"defects_flagged\": defects_flagged,\n",
    "        \"top_k_risks\": top_k_risks,\n",
    "        \"all_scores\": all_scores,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = random.sample(range(len(x_val)), min(5, len(x_val)))\n",
    "print(\"Production inference test:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for idx in test_indices:\n",
    "    fpath = x_val[idx]\n",
    "    result = predict_photo_quality(fpath, model, model_config)\n",
    "\n",
    "    print(f\"\\n  {result['filename']}\")\n",
    "    print(f\"    Quality:  {result['overall_quality'].upper()}\")\n",
    "    print(f\"    Severity: {result['severity_score']:.2f}\")\n",
    "\n",
    "    if result[\"defects_flagged\"]:\n",
    "        print(f\"    Flagged:\")\n",
    "        for d in result[\"defects_flagged\"]:\n",
    "            print(f\"      - {d['name']:15s} {d['confidence']:.3f}  (t={d['threshold']:.3f})\")\n",
    "    else:\n",
    "        print(f\"    Flagged:  none\")\n",
    "\n",
    "    print(f\"    Top-{TOP_K} risks:\")\n",
    "    for d in result[\"top_k_risks\"]:\n",
    "        print(f\"      - {d['name']:15s} {d['confidence']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 55)\n",
    "print(\"Example JSON response (for Laravel API):\")\n",
    "print(\"=\" * 55)\n",
    "sample_result = predict_photo_quality(x_val[test_indices[0]], model, model_config)\n",
    "print(json.dumps(sample_result, indent=2))\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  }
 ]
}